{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGFB1 Part 1 - Importing the data\n",
    "\n",
    "In this notebook, we take the data from the matrix, gene and cell files and create an AnnData matrix we can use for future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/numba/errors.py:105: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.4 anndata==0.6.19 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import scanpy\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "results_file = './write/tgfb1-1.h5ad'  # the file that will store the analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barcode filtering\n",
    "\n",
    "In order to filter the barcodes, we will open the barcodes done through Cell Ranger and return a set of the barcodes we want to filter the dropest matrix by. It is of the format:\n",
    "\n",
    "    AAACCTGAGACATAAC-1\n",
    "\n",
    "where ``AAACCTGAGACATAAC`` is a nucleotide barcode and ``1`` is the batch it corresponds to. We load this into a dictionary mapping barcodes to batches. We will not use the batches in the AnnData matrix, but it is still useful to cross-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barcode_set(path):\n",
    "    barcodes = {}\n",
    "\n",
    "    with open(\"barcodes.tsv\", \"r\") as f:\n",
    "        for line in f:\n",
    "            barcode, batch = line.rstrip().split('-')\n",
    "            batch = int(batch)\n",
    "            \n",
    "            barcodes[barcode] = batch\n",
    "    \n",
    "    return barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the dictionary from the Cell Ranger set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_barcode_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52a064b0da3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpawel_barcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_barcode_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"barcodes.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpawel_barcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_barcode_set' is not defined"
     ]
    }
   ],
   "source": [
    "pawel_barcodes = get_barcode_set(\"barcodes.tsv\")\n",
    "len(pawel_barcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading genes\n",
    "\n",
    "Create a function to load all the gene data from the dimension 1 CSV file, creating a list mapping gene IDs to genes.\n",
    "\n",
    "The gene file is of the format:\n",
    "\n",
    "    \"1\",\"TGFB1\"\n",
    "\n",
    "where `1` is a strictly increasing gene ID as found in the count matrix and `TGFB1` is the name of the gene. Create a list whose `n`th index is the name of the corresponding gene ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genes(batch, variant):\n",
    "    genes_result = []\n",
    "    genes_path = \"source/{}_{}_dim1.csv\".format(batch, variant)\n",
    "\n",
    "    with open(genes_path, \"r\") as genes:\n",
    "        line_no = 0\n",
    "\n",
    "        for gene in genes:\n",
    "            if not line_no:\n",
    "                line_no += 1\n",
    "                continue\n",
    "\n",
    "            id, name = gene.rstrip().replace('\"', '').split(\",\")\n",
    "            id = int(id)\n",
    "            \n",
    "            # These should be strictly increasing.\n",
    "            assert id == line_no\n",
    "\n",
    "            genes_result.append(name)\n",
    "            line_no += 1\n",
    "    \n",
    "    return genes_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading barcodes\n",
    "\n",
    "Create a function to load barcode data from the dimension 2 CSV file. It is of the format:\n",
    "\n",
    "    \"3\",\"AACCGTAATCGGGACCATCATCCC\"\n",
    "\n",
    "where `3` is a strictly increasing cell ID as found in the count matrix, and `AACCGTAATCGGGACCATCATCCC` is the full barcode according to this data set.\n",
    "\n",
    "Whenever a barcode is encountered, we check if its last 16 nt's have been found in the Cell Ranger barcode set.\n",
    "\n",
    "This returns a list whose `n`th element corresponds to the barcode of the cell with the corresponding ID, or `None` if the cell ID's barcode is not found in the Cell Ranger barcode set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_barcodes(batch, variant, good_barcodes):\n",
    "    result = []\n",
    "    barcode_path = \"source/{}_{}_dim2.csv\".format(batch, variant)  \n",
    "    \n",
    "    with open(barcode_path, \"r\") as barcodes:\n",
    "        # Skip R crap in first line.\n",
    "        next(barcodes)\n",
    "        \n",
    "        for i, line in enumerate(barcodes):\n",
    "            cell_id, full_barcode = line.rstrip().replace('\"', '').split(\",\")\n",
    "            barcode = full_barcode[-16:]\n",
    "            cell_id = int(cell_id)\n",
    "            \n",
    "            # The cell IDs should be continuous.\n",
    "            assert cell_id == (i + 1)\n",
    "            \n",
    "            if barcode not in good_barcodes:\n",
    "                result.append(None)\n",
    "            elif good_barcodes[barcode] != int(batch[-1]):\n",
    "                result.append(None)\n",
    "                #print(\"ERROR:\", barcode, \"is in good set but corresponds to batch\", good_barcodes[barcode])\n",
    "            else:\n",
    "                result.append(barcode)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an experiment, create a histogram to see how many cell IDs appear per cellular barcode. We can see that all of them except one have 4 cell IDs corresponding to a barcode, the rest of the barcode is the sample barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbarcodes = load_barcodes(\"S1\", \"exon\", pawel_barcodes)\\nhistogram = defaultdict(int)\\n\\nfor barcode in barcodes:\\n    if barcode:\\n        histogram[barcode] += 1\\n\\nhistogram\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to run experiment.\n",
    "\n",
    "\"\"\"\n",
    "barcodes = load_barcodes(\"S1\", \"exon\", pawel_barcodes)\n",
    "histogram = defaultdict(int)\n",
    "\n",
    "for barcode in barcodes:\n",
    "    if barcode:\n",
    "        histogram[barcode] += 1\n",
    "\n",
    "histogram\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading transcript count matrix\n",
    "\n",
    "The count matrix is of the format:\n",
    "\n",
    "    %\n",
    "    no_genes no_cells no_counts\n",
    "    19 1 1\n",
    "    34 1 1\n",
    "    [...]\n",
    "    33663 12318 1\n",
    "    33665 12318 35\n",
    "    33678 12318 1\n",
    "\n",
    "where the first number represents the gene, the second number represents the cell, and the third number represents the count.\n",
    "\n",
    "We then get a `cells` by `genes` count matrix indexed by the cell IDs and gene IDs as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript_matrix(batch, variant, genes, barcodes):\n",
    "    matrix_path = \"source/{}_{}.mmf\".format(batch, variant)\n",
    "    \n",
    "    matrix = None\n",
    "    \n",
    "    with open(matrix_path, \"r\") as f:\n",
    "        first_line = True\n",
    "        \n",
    "        for line in f:\n",
    "            if \"%\" in line:\n",
    "                continue\n",
    "            \n",
    "            gene, cell, count = [int(i) for i in line.rstrip().split()]\n",
    "            \n",
    "            if first_line:\n",
    "                assert gene == len(genes)\n",
    "                assert cell == len(barcodes)\n",
    "                \n",
    "                first_line = False\n",
    "                matrix = np.ndarray(shape=(cell, gene), dtype=np.dtype(np.int16))\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            gene_pos = gene - 1\n",
    "            cell_pos = cell - 1\n",
    "            \n",
    "            matrix[cell_pos, gene_pos] = count\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pandas DataFrame from count matrix\n",
    "\n",
    "Given a count matrix of size `genes x cells`, a list of length `genes` and a list of length `cells`, create a Pandas DataFrame with index `cells` and column labels from `genes`.\n",
    "\n",
    "As we have seen from the barcode loading function, we will have four rows in our table corresponding to the same barcode, and some of the data we get from the matrix does not correspond to a barcode in the Cell Ranger set. During this process, we will filter out all rows that do not have a valid Pawel barcode (i.e. index is None), and group and sum all (4) rows that have the same barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_matrix(m, genes, barcodes):\n",
    "    assert m.shape == (len(barcodes), len(genes))\n",
    "    \n",
    "    # Create a data frame from the count matrix, keyed by the barcode\n",
    "    # and gene annotations we created.\n",
    "    result = pandas.DataFrame(m)\n",
    "    result.index = barcodes\n",
    "    result.columns = genes\n",
    "    \n",
    "    # First, get rid of all the rows whose barcode is None. This means those\n",
    "    # cells were not found in the reference barcode set.\n",
    "    result = result[result.index.notnull()]\n",
    "    \n",
    "    # Then, since each barcode appears to correspond to four cell IDs,\n",
    "    # we get counts spread out across these four IDs. Let's collapse the duplicates.\n",
    "    result = result.groupby(by=lambda x: x).sum()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct DataFrame\n",
    "\n",
    "Given a batch identifier list (i.e. `[\"S1\", \"S2\"]`) and matrix name list (i.e. `[\"exon\", \"intron\"]`), create a Pandas DataFrame from the corresponding count matrices and gene/cell dimension file for each. In addition, update a set `genes_set` with all genes that have been encountered in this count matrix, as these are not normalized by default across matrices in a batch (unlike cell IDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataframes(batches, matrices, genes_set):\n",
    "    for batch_name in batches:    \n",
    "        prev_barcodes = None\n",
    "\n",
    "        for matrix_name in matrices:\n",
    "            print(\"Now processing\", batch_name, matrix_name)\n",
    "\n",
    "            genes = load_genes(batch_name, matrix_name)        \n",
    "            print(\"Genes list loaded at\", len(genes), \"items.\")\n",
    "\n",
    "            barcodes = load_barcodes(batch_name, matrix_name, pawel_barcodes)\n",
    "            print(\"Barcodes list loaded at\", len(barcodes), \"items.\")\n",
    "\n",
    "            print(\"Loading transcription matrix and converting to dataframe...\")\n",
    "            m = load_transcript_matrix(batch_name, matrix_name, genes, barcodes)\n",
    "            m = dataframe_from_matrix(m, genes, barcodes)\n",
    "\n",
    "            genes_set.update(m.columns)\n",
    "            print(\"Total gene set is now\", len(genes_set), \"long.\")\n",
    "\n",
    "            if prev_barcodes is not None:\n",
    "                assert m.index.equals(prev_barcodes)\n",
    "            else:\n",
    "                prev_barcodes = m.index\n",
    "\n",
    "            m.to_pickle(\"/tmp/{}_{}.pickle\".format(batch_name, matrix_name))\n",
    "            print(\"Count matrix with dimensions\", m.shape, \"created and pickled for\", batch_name, matrix_name)\n",
    "            print(\"\")\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize genes in DataFrames\n",
    "\n",
    "Given a batch identifier list (i.e. `[\"S1\", \"S2\"]`) and matrix name list (i.e. `[\"exon\", \"intron\"]`), load the corresponding DataFrames. Take the `genes_set` generated from the previous process and add to each dataframe the genes that are not encountered in that count matrix, and the counts to 0 for all cells. This is needed as all count matrices need to be the same dimension when the AnnData layers are generated. To normalize the list of genes, we will sort the columns alphabetically as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe_genes(batches, matrices, genes_set):\n",
    "    print(\"Normalizing dimensions of count matrices along genes...\")\n",
    "\n",
    "    for batch_name in batches:    \n",
    "        for matrix_name in matrices:\n",
    "            m = pandas.read_pickle(\"/tmp/{}_{}.pickle\".format(batch_name, matrix_name))\n",
    "\n",
    "            print(\"Old shape of\", batch_name, matrix_name, \"was\", m.shape)\n",
    "            missing_genes = genes_set - set(m.columns)\n",
    "            for missing_gene in missing_genes:\n",
    "                m[missing_gene] = 0\n",
    "            print(\"New shape is\", m.shape)\n",
    "\n",
    "            print(\"Reordering genes in alphabetical order...\")\n",
    "            print(\"Old column order was\", m.columns)\n",
    "            m = m.reindex(sorted(m.columns), axis=1)\n",
    "            print(\"New column order is\", m.columns)\n",
    "\n",
    "            m.to_pickle(\"/tmp/{}_{}.pickle\".format(batch_name, matrix_name))\n",
    "            print(\"Normalized count matrix for\", batch_name, matrix_name, \"pickled.\")\n",
    "            print(\"\")\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create layered AnnData object from batch matrices\n",
    "\n",
    "Create a layered AnnData object from frames for each individual batch. In practice, this takes all frames with names in a matrix list (i.e. `[\"intron\", \"exon\", \"spanning\"]`) for each batch (i.e. `[\"S1\", \"S2\"]`), and creates a layered AnnData object with layer names corresponding to `layer_names` (i.e. `[\"unspliced\", \"spliced\", \"ambiguous\"]`) from these frames.\n",
    "\n",
    "Frames should have identical dimensions, indices and column names for this to work.\n",
    "\n",
    "The layer with name `spliced` is implicitly used as the main count matrix of the AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anndata_from_frames(batches, matrices, layer_names):\n",
    "    results = []\n",
    "    \n",
    "    for batch in batches:\n",
    "        result = None\n",
    "        print(\"Now processing batch\", batch, \"...\")\n",
    "        \n",
    "        for matrix, layer in zip(matrices, layer_names):\n",
    "            print(\"Loading matrix\", matrix, \"...\")\n",
    "            m = pandas.read_pickle(\"/tmp/{}_{}.pickle\".format(batch, matrix))\n",
    "            \n",
    "            if not result:\n",
    "                print(\"Creating AnnData object...\")\n",
    "                \n",
    "                result = anndata.AnnData(shape=m.shape)\n",
    "                result.obs = pandas.DataFrame({\"cellular_barcode\": list(m.index)})\n",
    "                result.var = pandas.DataFrame({\"gene_names\": list(m.columns)})\n",
    "                \n",
    "            if layer == \"spliced\":\n",
    "                print(\"Layer is\", layer, \", adding it as main count matrix to object...\")\n",
    "                result.X = m\n",
    "            \n",
    "            print(\"Adding count matrix as layer\", layer, \"to AnnData object...\")\n",
    "            result.layers[layer] = m.values\n",
    "            print(\"\")\n",
    "\n",
    "        result.var_names = [gene for gene in result.var[\"gene_names\"]]\n",
    "        result.obs_names = [barcode for barcode in result.obs[\"cellular_barcode\"]]\n",
    "        result.obs_names_make_unique()\n",
    "        results.append(result)\n",
    "                \n",
    "        print(\"Final AnnData object is\", result)\n",
    "        \n",
    "        print(\"Saving layered AnnData object for batch\", batch, \"...\")\n",
    "        result.write(\"./write/{}-final.h5ad\".format(batch))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge AnnData objects along batches\n",
    "\n",
    "Given a list of AnnData objects corresponding to each batch, create one large AnnData object comprising all batches. Save merged AnnData object for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_anndata(batches):\n",
    "    result = None\n",
    "    to_merge = []\n",
    "    \n",
    "    for batch in batches:\n",
    "        if not result:\n",
    "            print(\"Merged AnnData file not yet created, making it from batch\", batch)\n",
    "            result = anndata.read_h5ad(\"./write/{}-final.h5ad\".format(batch))\n",
    "            print(\"Merged AnnData file is now\", result)\n",
    "        else:\n",
    "            print(\"Loading batch\", batch)\n",
    "            curr = anndata.read_h5ad(\"./write/{}-final.h5ad\".format(batch), backed=\"r+\")\n",
    "            print(\"Loaded AnnData file is\", curr, \", appending to list of objects to concatenate...\")\n",
    "            to_merge.append(curr)\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"\")        \n",
    "    print(\"Concatenating list\", to_merge, \"to original file\")\n",
    "    result = result.concatenate(*to_merge, batch_categories=batches, index_unique=None)\n",
    "    print(\"Concatenated AnnData object is\", result, \", saving it to disk...\")\n",
    "    result.write(\"./write/merged-final.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the procedures above\n",
    "Create the variables for this experiment and run the procedures above, creating an AnnData matrix used in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = ('S1', 'S2')\n",
    "matrices = ('exon', 'intron', 'spanning')\n",
    "layer_names = ('spliced', 'unspliced', 'ambiguous')\n",
    "all_genes = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_dataframes(batches, matrices, all_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dataframe_genes(batches, matrices, all_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_anndata_from_frames(batches, matrices, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged AnnData file not yet created, making it from batch S1\n",
      "Merged AnnData file is now AnnData object with n_obs × n_vars = 5194 × 36246 \n",
      "    obs: 'cellular_barcode'\n",
      "    var: 'gene_names'\n",
      "    layers: 'ambiguous', 'spliced', 'unspliced'\n",
      "\n",
      "Loading batch S2\n",
      "Loaded AnnData file is AnnData object with n_obs × n_vars = 7073 × 36246 backed at 'write/S2-final.h5ad'\n",
      "    obs: 'cellular_barcode'\n",
      "    var: 'gene_names'\n",
      "    layers: 'ambiguous', 'spliced', 'unspliced' , appending to list of objects to concatenate...\n",
      "\n",
      "\n",
      "Concatenating list [AnnData object with n_obs × n_vars = 7073 × 36246 backed at 'write/S2-final.h5ad'\n",
      "    obs: 'cellular_barcode'\n",
      "    var: 'gene_names'\n",
      "    layers: 'ambiguous', 'spliced', 'unspliced'] to original file\n",
      "Concatenated AnnData object is AnnData object with n_obs × n_vars = 12267 × 36246 \n",
      "    obs: 'batch', 'cellular_barcode'\n",
      "    var: 'gene_names-S1', 'gene_names-S2'\n",
      "    layers: 'ambiguous', 'spliced', 'unspliced' , saving it to disk...\n"
     ]
    }
   ],
   "source": [
    "create_merged_anndata(batches)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
